{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import contractions\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'cardiffnlp/twitter-roberta-base-emotion-multilabel-latest'\n",
    "model_file = \"twitter-roberta-base-emotion-multilabel-latest\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "max_len = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.bert_model = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = torch.nn.Dropout(0.4)\n",
    "        self.linear = torch.nn.Linear(768, 3) # input:embedding length (768), output:number of labels (3)\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids) :\n",
    "        bert_output = self.bert_model(input_ids, attention_mask, token_type_ids).pooler_output\n",
    "        bert_output = self.dropout(bert_output)\n",
    "        final_output = self.linear(bert_output)\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = Model()\n",
    "trained_model.load_state_dict(torch.load(f'./{model_file}.pth', map_location=device))\n",
    "trained_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for getting sentiment category of a text\n",
    "def get_category(model, text) :\n",
    "    punctuation_marks = string.punctuation.replace(\"'\",\"\").replace(\"-\",\"\")\n",
    "    def remove_punctuation(text):\n",
    "        return text.translate(str.maketrans(punctuation_marks, \" \"*len(punctuation_marks)))\n",
    "\n",
    "    def convert_lower(text) :\n",
    "        return text.lower()\n",
    "\n",
    "    with open(\"./chat_words.txt\", \"r\") as f :\n",
    "        chat_words = json.load(f)\n",
    "\n",
    "    def expand_chat_words(text) :\n",
    "        return \" \".join([chat_words[i] if i in chat_words else i for i in text.split()])\n",
    "\n",
    "    def expand_contractions(text):\n",
    "        return contractions.fix(text)\n",
    "\n",
    "    def substitute_laugh(text) :\n",
    "        return re.sub(\"ha\", \"laugh \", text)\n",
    "\n",
    "    def remove_non_latin_emoji(text):\n",
    "        return re.sub(r\"[^A-Za-z- '\\U0001F300-\\U0001F64F\\U0001F680-\\U0001F6FF\\U0001F910-\\U0001F96B\\U0001F980-\\U0001F9E0]\", '', text)\n",
    "\n",
    "    def preprocessing_pipeline(text) :\n",
    "        text = text.replace(\"[NAME]\", \"\").replace(\"[RELIGION]\", \"\")\n",
    "        text = remove_punctuation(text)\n",
    "        text = re.sub(r'[‚Äô‚Äò¬¥`‚Äú‚Äù\"]', \"'\", text)\n",
    "        text = convert_lower(text)\n",
    "        text = substitute_laugh(text)\n",
    "        text = expand_chat_words(text)\n",
    "        text = expand_contractions(text)\n",
    "        text = remove_non_latin_emoji(text)\n",
    "        return text\n",
    "\n",
    "    t = tokenizer.encode_plus(preprocessing_pipeline(text),\n",
    "                                add_special_tokens=True,\n",
    "                                max_length=max_len,\n",
    "                                padding=\"max_length\",\n",
    "                                return_token_type_ids=True,\n",
    "                                return_attention_mask=True,\n",
    "                                return_tensors=\"pt\",\n",
    "                                truncation=True)\n",
    "\n",
    "    input_ids = t[\"input_ids\"].to(device, dtype = torch.long)\n",
    "    attention_mask = t[\"attention_mask\"].to(device, dtype = torch.long)\n",
    "    token_type_ids = t[\"token_type_ids\"].to(device, dtype = torch.long)\n",
    "\n",
    "    calculated_labels = model(input_ids, attention_mask, token_type_ids)\n",
    "    results = (dict(zip([\"positive\", \"negative\", \"neutral\"],torch.sigmoid(calculated_labels).cpu().detach().numpy().tolist()[0])))\n",
    "\n",
    "    return max(results, key=results.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentimental_profile(model, sentences_personA, sentences_personB) :\n",
    "    # get sentiments for sentences for every person\n",
    "    categories_personA = [get_category(model, item) for item in sentences_personA]\n",
    "    categories_personB = [get_category(model, item) for item in sentences_personB]\n",
    "\n",
    "    # find frequencies of sentiments for every person\n",
    "    frequencies_personA = Counter(categories_personA)\n",
    "    frequencies_personB = Counter(categories_personB)\n",
    "\n",
    "    # find non-negative intensity for every person\n",
    "    intensity_personA = (frequencies_personA[\"positive\"] + frequencies_personA[\"neutral\"])/len(categories_personA)\n",
    "    intensity_personB = (frequencies_personB[\"positive\"] + frequencies_personB[\"neutral\"])/len(categories_personB)\n",
    "\n",
    "    # find interaction intensity as arithmetic mean\n",
    "    return (intensity_personA + intensity_personB)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue = [\n",
    "    \"Hey, what's up? üòä\",\n",
    "    \"Not much. I'm just really frustrated about the programming project we turned in yesterday. üòî\",\n",
    "    \"Why is that? What happened? üòü\",\n",
    "    \"I feel like you didn't do your part and it really hurt our grade. You were supposed to work on the front-end and you barely did anything. üòû\",\n",
    "    \"What are you talking about? I worked really hard on the front-end! You were the one who was supposed to do the back-end and you didn't even finish it!\",\n",
    "    \"That's not true! I finished everything on time and it was all working perfectly. You were the one who was slacking off and not contributing anything. üò†ü§¨\",\n",
    "    \"I can't believe you're saying that! I worked just as hard as you did and I did everything I was supposed to do. You're just trying to blame me for your own mistakes. üò†üëéüèΩ\",\n",
    "    \"No, I'm not! You're the one who messed everything up and now we're both going to suffer because of it. I can't believe you're being so selfish and stubborn about this. üò†\",\n",
    "    \"I'm not being selfish or stubborn! You're just trying to make me look bad so you can feel better about yourself. It's not going to work. We both know what really happened. ü§Æ\",\n",
    "    \"I can't even talk to you right now. You're being so unreasonable and unfair. I thought we were friends, but I guess I was wrong. üòî\",\n",
    "    \"I thought so too, but I guess I was wrong too. Maybe we should just work on our own projects from now on. It's obviously not working out between us.\"\n",
    "]\n",
    "\n",
    "# get the intensity of chat\n",
    "create_sentimental_profile(trained_model, dialogue[::2], dialogue[1::2])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
