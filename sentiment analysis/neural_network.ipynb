{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "model_name = 'cardiffnlp/twitter-roberta-base-emotion-multilabel-latest'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "max_len = 128\n",
    "batch_size = 16\n",
    "epochs = 4\n",
    "learning_rate = 1e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset) :\n",
    "    def __init__(self, df) :\n",
    "        self.text = df[\"text\"]\n",
    "        self.targets = df.iloc[:,1:].values\n",
    "\n",
    "    def __len__(self) :\n",
    "        return len(self.text)\n",
    "\n",
    "    def tokenize_text(self, text) :\n",
    "        return tokenizer.encode_plus(text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_token_type_ids=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True)\n",
    "\n",
    "    def __getitem__(self, index) :\n",
    "        tokenized_text = self.tokenize_text(self.text[index])\n",
    "        return {\n",
    "        \"input_ids\": tokenized_text[\"input_ids\"].flatten(),\n",
    "        \"attention_mask\": tokenized_text[\"attention_mask\"].flatten(),\n",
    "        \"token_type_ids\": tokenized_text[\"token_type_ids\"].flatten(),\n",
    "        \"targets\": torch.FloatTensor(self.targets[index])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./train.csv\")\n",
    "val_df = pd.read_csv(\"./validation.csv\")\n",
    "test_df = pd.read_csv(\"./test.csv\")\n",
    "\n",
    "train_dataset = Dataset(train_df)\n",
    "val_dataset = Dataset(val_df)\n",
    "test_dataset = Dataset(test_df)\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)\n",
    "\n",
    "val_data_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.bert_model = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = torch.nn.Dropout(0.4)\n",
    "        self.linear = torch.nn.Linear(768, 3) # input:embedding length (768), output:number of labels (3)\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids) :\n",
    "        bert_output = self.bert_model(input_ids, attention_mask, token_type_ids).pooler_output\n",
    "        bert_output = self.dropout(bert_output)\n",
    "        final_output = self.linear(bert_output)\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights_train = (1-train_df.iloc[:,1:].value_counts(normalize=True)).values\n",
    "class_weights_train = torch.from_numpy(class_weights_train).float().to(device)\n",
    "\n",
    "class_weights_validation = (1-val_df.iloc[:,1:].value_counts(normalize=True)).values\n",
    "class_weights_validation = torch.from_numpy(class_weights_validation).float().to(device)\n",
    "\n",
    "class_weights_test = (1-test_df.iloc[:,1:].value_counts(normalize=True)).values\n",
    "class_weights_test = torch.from_numpy(class_weights_test).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(output_values, target_values, weights):\n",
    "    return torch.nn.BCEWithLogitsLoss(weight=weights)(output_values, target_values)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for training in an epoch\n",
    "def train_for_one_epoch(model, training_loader, optimizer) :\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    model.train()\n",
    "    training_loss = 0\n",
    "    # loop for every batch\n",
    "    for batch_data in training_loader :\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch_data[\"input_ids\"].to(device, dtype = torch.long)\n",
    "        attention_mask = batch_data[\"attention_mask\"].to(device, dtype = torch.long)\n",
    "        token_type_ids = batch_data[\"token_type_ids\"].to(device, dtype = torch.long)\n",
    "        targets = batch_data[\"targets\"].to(device, dtype = torch.float)\n",
    "        # find model output\n",
    "        calculated_labels = model(input_ids, attention_mask, token_type_ids)\n",
    "        # find loss aka difference of output and target labels\n",
    "        loss = loss_function(calculated_labels, targets, class_weights_train)\n",
    "        # get target labels and predictions\n",
    "        labels.extend(targets.cpu().detach().numpy().tolist())\n",
    "        predictions.extend(calculated_labels.cpu().detach().numpy().tolist())\n",
    "        # compute the gradient of the loss with respect to each weight\n",
    "        loss.backward()\n",
    "        # adjust the weights by the gradients collected in the backward pass.\n",
    "        optimizer.step()\n",
    "        training_loss += loss.item()\n",
    "        \n",
    "    # find loss per batch\n",
    "    training_loss /= len(training_loader.dataset)\n",
    "    # prediction for a label is 1 if itɐs >= 0.5. Otherwise itɐs 0\n",
    "    predictions = np.array(predictions) >= 0.5\n",
    "\n",
    "    # find f1 score (macro)\n",
    "    f1_macro = metrics.f1_score(labels, predictions, average=\"macro\")\n",
    "    print(\"\\t training: \" + f\"loss: {training_loss:.3f}, F1 macro: {f1_macro:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for validating in an epoch\n",
    "def validate_for_one_epoch(model, validation_loader) :\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    model.eval()\n",
    "    validation_loss = 0\n",
    "    with torch.no_grad() :\n",
    "    # loop for every batch\n",
    "        for batch_data in validation_loader :\n",
    "            input_ids = batch_data[\"input_ids\"].to(device, dtype = torch.long)\n",
    "            attention_mask = batch_data[\"attention_mask\"].to(device, dtype = torch.long)\n",
    "            token_type_ids = batch_data[\"token_type_ids\"].to(device, dtype = torch.long)\n",
    "            targets = batch_data[\"targets\"].to(device, dtype = torch.float)\n",
    "            # find model output\n",
    "            calculated_labels = model(input_ids, attention_mask, token_type_ids)\n",
    "            # find loss aka difference of output and target labels\n",
    "            validation_loss += loss_function(calculated_labels, targets, class_weights_validation).item()\n",
    "            # get target labels and predictions\n",
    "            labels.extend(targets.cpu().detach().numpy().tolist())\n",
    "            predictions.extend(calculated_labels.cpu().detach().numpy().tolist())\n",
    "\n",
    "    # find loss per batch\n",
    "    validation_loss /= len(validation_loader.dataset)\n",
    "\n",
    "    # prediction for a label is 1 if itɐs >= 0.5. Otherwise itɐs 0\n",
    "    predictions = np.array(predictions) >= 0.5\n",
    "    \n",
    "    # find f1 score (macro)\n",
    "    f1_macro = metrics.f1_score(labels, predictions, average=\"macro\")\n",
    "    print(\"\\t validation: \" + f\"loss: {validation_loss:.3f}, F1 macro: {f1_macro:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for testing\n",
    "def test(model, test_loader) :\n",
    "    predictions = []\n",
    "    labels = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad() :\n",
    "        for batch_data in test_loader :\n",
    "            input_ids = batch_data[\"input_ids\"].to(device, dtype = torch.long)\n",
    "            attention_mask = batch_data[\"attention_mask\"].to(device, dtype = torch.long)\n",
    "            token_type_ids = batch_data[\"token_type_ids\"].to(device, dtype = torch.long)\n",
    "            targets = batch_data[\"targets\"].to(device, dtype = torch.float)\n",
    "            # find model output\n",
    "            calculated_labels = model(input_ids, attention_mask, token_type_ids)\n",
    "            # get target labels and predictions\n",
    "            labels.extend(targets.cpu().detach().numpy().tolist())\n",
    "            predictions.extend(calculated_labels.cpu().detach().numpy().tolist())\n",
    "                               \n",
    "    # prediction for a label is 1 if itɐs >= 0.5. Otherwise itɐs 0\n",
    "    predictions = np.array(predictions) >= 0.5\n",
    "\n",
    "    # find f1 scores for each class and macro\n",
    "    f1_scores = metrics.f1_score(labels, predictions, average=None)\n",
    "    f1_macro = metrics.f1_score(labels, predictions, average=\"macro\")\n",
    "\n",
    "    print(\"\\t testing: \" + f\"F1 scores: {dict(zip(train_df.columns[1:].tolist(), f1_scores))}\")\n",
    "    print(f\"\\t F1 macro: {f1_macro}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for training, validating for n_epochs and ultimately testing\n",
    "def train_for_n_epochs(model, training_loader, validation_loader, test_loader, optimizer, n_epochs):\n",
    "    for epoch in range(n_epochs) :\n",
    "        print(f\"epoch {epoch + 1}\")\n",
    "        train_for_one_epoch(model, training_loader, optimizer)\n",
    "        validate_for_one_epoch(model, validation_loader)\n",
    "        print()\n",
    "        test(model, test_loader)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = train_for_n_epochs(model, train_data_loader, val_data_loader, test_data_loader, optimizer, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions\n",
    "import re\n",
    "import string\n",
    "import emoji\n",
    "import json\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for getting sentiment category of a text\n",
    "def get_category(model, text) :\n",
    "    def convert_emoji(text):\n",
    "        text = emoji.demojize(text).replace(\":\",\" \")\n",
    "        return text\n",
    "    \n",
    "    punctuation_marks = string.punctuation.replace(\"'\",\"\").replace(\"-\",\"\")\n",
    "    def remove_punctuation(text):\n",
    "        return text.translate(str.maketrans(punctuation_marks, \" \"*len(punctuation_marks)))\n",
    "    \n",
    "    def convert_lower(text) :\n",
    "        return text.lower()\n",
    "    \n",
    "    with open(\"./chat_words.txt\", \"r\") as f :\n",
    "        chat_words = json.load(f)\n",
    "    \n",
    "    def expand_chat_words(text) :\n",
    "        return \" \".join([chat_words[i] if i in chat_words else i for i in text.split()])\n",
    "    \n",
    "    def expand_contractions(text):\n",
    "        return contractions.fix(text)\n",
    "    \n",
    "    def substitute_laugh(text) :\n",
    "        return re.sub(\"ha\", \"laugh \", text)\n",
    "    \n",
    "    def remove_non_latin_emoji(text):\n",
    "        return re.sub(r\"[^A-Za-z- '\\U0001F300-\\U0001F64F\\U0001F680-\\U0001F6FF\\U0001F910-\\U0001F96B\\U0001F980-\\U0001F9E0]\", '', text)\n",
    "\n",
    "    def preprocessing_pipeline(text) :\n",
    "        text = text.replace(\"[NAME]\", \"\").replace(\"[RELIGION]\", \"\")\n",
    "        text = remove_punctuation(text)\n",
    "        text = re.sub(r'[’‘´`“”\"]', \"'\", text)\n",
    "        text = convert_lower(text)\n",
    "        text = substitute_laugh(text)\n",
    "        text = expand_chat_words(text)\n",
    "        text = expand_contractions(text)\n",
    "        text = remove_non_latin_emoji(text)\n",
    "        return text\n",
    "    \n",
    "    t = tokenizer.encode_plus(preprocessing_pipeline(text),\n",
    "                                add_special_tokens=True,\n",
    "                                max_length=max_len,\n",
    "                                padding=\"max_length\",\n",
    "                                return_token_type_ids=True,\n",
    "                                return_attention_mask=True,\n",
    "                                return_tensors=\"pt\",\n",
    "                                truncation=True)\n",
    "    \n",
    "    input_ids = t[\"token_type_ids\"].to(device, dtype = torch.long)\n",
    "    attention_mask = t[\"token_type_ids\"].to(device, dtype = torch.long)\n",
    "    token_type_ids = t[\"token_type_ids\"].to(device, dtype = torch.long)\n",
    "\n",
    "    calculated_labels = model(input_ids, attention_mask, token_type_ids)\n",
    "    results = (dict(zip([\"positive\", \"negative\", \"neutral\"],torch.sigmoid(calculated_labels).cpu().detach().numpy().tolist()[0])))\n",
    "    \n",
    "    return max(results, key=results.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentimental_profile(model, sentences_personA, sentences_personB) :\n",
    "    # get sentiments for sentences for every person\n",
    "    categories_personA = [get_category(model, item) for item in sentences_personA]\n",
    "    categories_personB = [get_category(model, item) for item in sentences_personB]\n",
    "\n",
    "    # find frequencies of sentiments for every person\n",
    "    frequencies_personA = Counter(categories_personA)\n",
    "    frequencies_personB = Counter(categories_personB)\n",
    "\n",
    "    # find non-negative intensity for every person\n",
    "    intensity_personA = (frequencies_personA[\"positive\"] + frequencies_personA[\"neutral\"])/len(categories_personA)\n",
    "    intensity_personB = (frequencies_personB[\"positive\"] + frequencies_personB[\"neutral\"])/len(categories_personB)\n",
    "    \n",
    "    # find interaction intensity as arithmetic mean\n",
    "    return (intensity_personA + intensity_personB)/2"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
